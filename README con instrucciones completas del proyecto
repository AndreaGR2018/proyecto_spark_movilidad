ğŸš¦ Proyecto Spark Movilidad

AnÃ¡lisis de movilidad en BogotÃ¡ con Apache Spark y Kafka

ğŸ§© IntroducciÃ³n

Este proyecto analiza datos de movilidad en BogotÃ¡ utilizando Apache Spark y Apache Kafka para el procesamiento tanto batch como en tiempo real.
El conjunto de datos contiene informaciÃ³n sobre los medios de transporte utilizados por los ciudadanos en sus viajes diarios, permitiendo identificar patrones de desplazamiento y comportamientos de movilidad urbana.

ğŸ—ºï¸ DefiniciÃ³n del problema y conjunto de datos

El propÃ³sito de este proyecto es analizar los patrones de movilidad de los ciudadanos de BogotÃ¡ a partir de datos de encuestas sobre viajes, con el fin de identificar:

Los medios de transporte mÃ¡s utilizados.

Los horarios de mayor flujo de viajes.

Los tiempos promedio de desplazamiento segÃºn el medio de transporte.

El conjunto de datos utilizado proviene de la Encuesta de Movilidad de BogotÃ¡ (Encuesta_movilidad.csv), disponible pÃºblicamente en fuentes abiertas como Kaggle y el portal de datos abiertos de Colombia.
Este dataset contiene informaciÃ³n de viajes con campos como:
ID_ENCUESTA, NUMERO_PERSONA, MOTIVOVIAJE, MUNICIPIO_DESTINO, HORA_INICIO, HORA_FIN, TIEMPO_CAMINO y MEDIO_PRE.

âš™ï¸ Arquitectura de la SoluciÃ³n

La arquitectura incluye los siguientes componentes principales:

Kafka ğŸ“¨: para la transmisiÃ³n de mensajes en tiempo real.

Spark Structured Streaming âš™ï¸: para el procesamiento continuo de los datos recibidos desde Kafka.

Docker Compose ğŸ³: para levantar los servicios de Kafka y Zookeeper fÃ¡cilmente.

Python ğŸ: para generar los mensajes (productor) y procesarlos (consumidor).

ğŸ“ Archivos Principales
Archivo	DescripciÃ³n
batch_process.py	Realiza el anÃ¡lisis inicial del dataset en modo batch (limpieza, transformaciÃ³n y cÃ¡lculo de promedios).
producer_generator.py	EnvÃ­a los registros del dataset al tÃ³pico de Kafka (movilidad_bogota).
streaming_kafka.py	Consume los mensajes desde Kafka y los procesa en tiempo real con Spark.
docker-compose.yml	Define los contenedores de Kafka y Zookeeper.
Encuesta_movilidad.csv	Dataset base con la informaciÃ³n de los registros.
ğŸ§® Procesamiento Batch

El script batch_process.py realiza el anÃ¡lisis inicial del dataset de movilidad en formato batch.
Incluye tareas de limpieza, transformaciÃ³n y cÃ¡lculo de promedios por medio de transporte.

EjecuciÃ³n
spark-submit batch_process.py


Los resultados procesados se guardan automÃ¡ticamente en la carpeta resultados/ en formato CSV.

ğŸ“¸ Ejemplo de salida del procesamiento batch:

MEDIO_PRE     Promedio_Tiempo
bus           36.2
carro         29.4
bicicleta     18.7
peaton        24.9

ğŸ” Procesamiento en Tiempo Real (Streaming)

El procesamiento en tiempo real se realiza con Kafka + Spark Streaming:

1ï¸âƒ£ Kafka recibe los mensajes generados por el productor (producer_generator.py).
2ï¸âƒ£ Spark Streaming (en streaming_kafka.py) consume esos mensajes desde el tÃ³pico.
3ï¸âƒ£ Los datos se agrupan por tipo de medio de transporte (MEDIO_PRE) y se muestran los resultados en tiempo real.

â–¶ï¸ EjecuciÃ³n del Proyecto
1ï¸âƒ£ Levantar los contenedores de Kafka y Zookeeper

Desde el directorio del proyecto:

sudo docker-compose up -d

2ï¸âƒ£ Ejecutar el Productor (envÃ­a datos a Kafka)
python3 producer_generator.py

3ï¸âƒ£ Ejecutar el Consumidor (procesa los datos en Spark)

En otra terminal:

spark-submit streaming_kafka.py

ğŸ“Š VisualizaciÃ³n de Resultados

El sistema imprime en consola los resultados en tiempo real, mostrando el conteo de viajes por tipo de medio de transporte.

ğŸ“¸ Ejemplo de salida del streaming:

+-------------+-----+
| MEDIO_PRE   |count|
+-------------+-----+
| transmilenio| 235 |
| bus         | 204 |
| bicicleta   | 128 |
| peaton      | 226 |
| carro       | 142 |
| taxi        | 80  |
| moto        | 135 |
+-------------+-----+


AdemÃ¡s, el procesamiento batch genera archivos CSV con resultados agregados en la carpeta resultados/.

ğŸ”— Enlaces

ğŸ“‚ Repositorio del proyecto: GitHub - Proyecto Spark Movilidad

ğŸ¥ Video explicativo: (pendiente de grabar)

ğŸ§‘â€ğŸ’» Autores

Proyecto desarrollado por:
Andrea Gordillo Rojas
Universidad Nacional Abierta y a Distancia (UNAD)
Curso: Big Data â€“ 2025
