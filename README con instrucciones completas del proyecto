ğŸš¦ Proyecto Spark Movilidad

AnÃ¡lisis de movilidad en BogotÃ¡ con Apache Spark y Kafka

ğŸ§© IntroducciÃ³n

Este proyecto analiza datos de movilidad en BogotÃ¡ utilizando Apache Spark y Apache Kafka para el procesamiento tanto batch como en tiempo real.
El conjunto de datos contiene informaciÃ³n sobre los medios de transporte utilizados por los ciudadanos en sus viajes diarios, permitiendo identificar patrones de desplazamiento y comportamientos de movilidad urbana.

ğŸ—ºï¸ DefiniciÃ³n del problema y conjunto de datos

El propÃ³sito de este proyecto es analizar los patrones de movilidad de los ciudadanos de BogotÃ¡ a partir de datos de encuestas sobre viajes, con el fin de identificar:

Los medios de transporte mÃ¡s utilizados.

Los horarios de mayor flujo de viajes.

Los tiempos promedio de desplazamiento segÃºn el medio de transporte.

El conjunto de datos utilizado proviene de la Encuesta de Movilidad de BogotÃ¡ (Encuesta_movilidad.csv), disponible pÃºblicamente en fuentes abiertas como Kaggle y el portal de datos abiertos de Colombia.
Este dataset contiene informaciÃ³n de viajes con campos como:
ID_ENCUESTA, NUMERO_PERSONA, MOTIVOVIAJE, MUNICIPIO_DESTINO, HORA_INICIO, HORA_FIN, TIEMPO_CAMINO y MEDIO_PRE.

âš™ï¸ Arquitectura de la SoluciÃ³n

La arquitectura incluye los siguientes componentes principales:

Kafka ğŸ“¨: para la transmisiÃ³n de mensajes en tiempo real.

Spark Structured Streaming âš™ï¸: para el procesamiento continuo de los datos recibidos desde Kafka.

Docker Compose ğŸ³: para levantar los servicios de Kafka y Zookeeper fÃ¡cilmente.

Python ğŸ: para generar los mensajes (productor) y procesarlos (consumidor).

ğŸ“ Archivos Principales
Archivo	DescripciÃ³n
batch_process.py	Realiza el anÃ¡lisis inicial del dataset en modo batch (limpieza, transformaciÃ³n y cÃ¡lculo de promedios).
producer_generator.py	EnvÃ­a los registros del dataset al tÃ³pico de Kafka (movilidad_bogota).
streaming_kafka.py	Consume los mensajes desde Kafka y los procesa en tiempo real con Spark.
docker-compose.yml	Define los contenedores de Kafka y Zookeeper.
Encuesta_movilidad.csv	Dataset base con la informaciÃ³n de los registros.
ğŸš€ EjecuciÃ³n del procesamiento batch (Apache Spark)
ğŸ“Œ DescripciÃ³n

El procesamiento batch se encarga de analizar los datos histÃ³ricos de movilidad ciudadana en BogotÃ¡, obtenidos de la encuesta de movilidad.
Este proceso permite identificar patrones de uso de transporte, horarios de mayor flujo y tiempos promedio de desplazamiento.

El script principal es:

batch_process.py

âš™ï¸ EjecuciÃ³n del script

Para ejecutar el procesamiento batch desde el entorno Hadoop/Spark (en la mÃ¡quina virtual Ubuntu Server), se usa el siguiente comando:

cd ~/datasets/encuesta_movilidad
spark-submit batch_process.py


ğŸ’¡ AsegÃºrate de haber iniciado los servicios de Hadoop y configurado correctamente las variables de entorno de Spark antes de ejecutar el comando.

ğŸ§® Proceso realizado

El script realiza las siguientes operaciones:

Carga del dataset desde un archivo CSV (encuesta de movilidad).

Limpieza y transformaciÃ³n de datos, eliminando valores nulos y columnas innecesarias.

AgrupaciÃ³n y anÃ¡lisis de los viajes por medio de transporte, hora y duraciÃ³n promedio.

GeneraciÃ³n de resultados en consola o archivos CSV, listos para visualizaciÃ³n y anÃ¡lisis posterior.

ğŸ“¸ Ejemplo de salida

Evidencia de la ejecuciÃ³n del procesamiento batch en la consola de Spark:

+------------------+-------------+-------------------+
|medio_transporte  |cantidad_viajes|tiempo_promedio_min|
+------------------+-------------+-------------------+
|Transmilenio      |  14532      |       43.2        |
|Bus Urbano        |   9560      |       39.7        |
|AutomÃ³vil Particular |  7843     |       35.4        |
|Bicicleta         |   3241      |       27.1        |
+------------------+-------------+-------------------+

ğŸ“ Resultados

Los resultados generados se almacenan en la carpeta local:

~/datasets/encuesta_movilidad/output_batch/


Cada archivo contiene los datos procesados por Spark listos para anÃ¡lisis o visualizaciÃ³n.

ğŸ§  Conclusiones

El procesamiento batch permitiÃ³ obtener una visiÃ³n general de los patrones de movilidad, destacando los medios de transporte con mayor uso y los tiempos promedio de desplazamiento.
Estos resultados sirven como base para comparar con el anÃ¡lisis en tiempo real (streaming) mediante Apache Kafka y Spark Streaming.

ğŸ” Procesamiento en Tiempo Real (Streaming)

El procesamiento en tiempo real se realiza con Kafka + Spark Streaming:

1ï¸âƒ£ Kafka recibe los mensajes generados por el productor (producer_generator.py).
2ï¸âƒ£ Spark Streaming (en streaming_kafka.py) consume esos mensajes desde el tÃ³pico.
3ï¸âƒ£ Los datos se agrupan por tipo de medio de transporte (MEDIO_PRE) y se muestran los resultados en tiempo real.

â–¶ï¸ EjecuciÃ³n del Proyecto
1ï¸âƒ£ Levantar los contenedores de Kafka y Zookeeper

Desde el directorio del proyecto:

sudo docker-compose up -d

2ï¸âƒ£ Ejecutar el Productor (envÃ­a datos a Kafka)
python3 producer_generator.py

3ï¸âƒ£ Ejecutar el Consumidor (procesa los datos en Spark)

En otra terminal:

spark-submit streaming_kafka.py

ğŸ“Š VisualizaciÃ³n de Resultados

El sistema imprime en consola los resultados en tiempo real, mostrando el conteo de viajes por tipo de medio de transporte.

ğŸ“¸ Ejemplo de salida del streaming:

+-------------+-----+
| MEDIO_PRE   |count|
+-------------+-----+
| transmilenio| 235 |
| bus         | 204 |
| bicicleta   | 128 |
| peaton      | 226 |
| carro       | 142 |
| taxi        | 80  |
| moto        | 135 |
+-------------+-----+


AdemÃ¡s, el procesamiento batch genera archivos CSV con resultados agregados en la carpeta resultados/.
---

## ğŸ“¸ Evidencias del Proyecto

A continuaciÃ³n, se presentan las principales evidencias del funcionamiento del proyecto, desde el procesamiento batch hasta el flujo de datos en tiempo real con Kafka y Spark Streaming.

### ğŸ§¾ 1. Procesamiento Batch
EjecuciÃ³n del script `batch_process.py` para procesar el conjunto de datos y generar los resultados agregados.
  
![Procesamiento Batch](evidencias/01_datos_batch_process.png)

---

### ğŸ“Š 2. Resultados del Procesamiento Batch
VisualizaciÃ³n del archivo generado con los conteos por tipo de medio de transporte.

![Resultados CSV](evidencias/02_resultados_batch_csv.png)

---

### ğŸš€ 3. Productor Kafka Enviando Datos
SimulaciÃ³n del flujo de datos en tiempo real desde el productor hacia el tÃ³pico de Kafka.

![Productor Kafka](evidencias/03_kafka_productor.png)

---

### âš™ï¸ 4. Spark Streaming en EjecuciÃ³n
EjecuciÃ³n del proceso `streaming_kafka.py` mostrando los resultados del anÃ¡lisis en tiempo real.

![Spark Streaming](evidencias/04_spark_streaming.png)

---

### ğŸ’» 5. Repositorio en GitHub
Estructura final del repositorio con el cÃ³digo fuente, scripts y documentaciÃ³n del proyecto.

![Repositorio GitHub](evidencias/05_github_repo.png)

---

ğŸ”— Enlaces

ğŸ“‚ Repositorio del proyecto: GitHub - Proyecto Spark Movilidad

ğŸ¥ Video explicativo: (pendiente de grabar)

ğŸ§‘â€ğŸ’» Autores

Proyecto desarrollado por:
Andrea Gordillo Rojas
Universidad Nacional Abierta y a Distancia (UNAD)
Curso: Big Data â€“ 2025
