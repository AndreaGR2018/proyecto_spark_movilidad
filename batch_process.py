from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, avg, round, desc

# 1ï¸âƒ£ Crear la sesiÃ³n de Spark
spark = SparkSession.builder \
    .appName("ProcesamientoBatch_EncuestaMovilidad") \
    .getOrCreate()

print("\nğŸš€ Iniciando procesamiento batch...")

# 2ï¸âƒ£ Cargar el archivo CSV
df = spark.read.csv("/home/vboxuser/datasets/Encuesta_movilidad.csv", header=True, inferSchema=True)

# 3ï¸âƒ£ Mostrar estructura inicial
print("\nğŸ“‹ Columnas del DataFrame:")
print(df.columns)
print(f"\nğŸ“Š Total de registros iniciales: {df.count()}")

# 4ï¸âƒ£ Mostrar muestra aleatoria
print("\nğŸ” Muestra aleatoria de registros:")
df.sample(fraction=0.01, seed=42).show(5, truncate=False)

# 5ï¸âƒ£ Resumen estadÃ­stico del tiempo de camino
print("\nğŸ“ˆ Resumen estadÃ­stico de 'TIEMPO_CAMINO':")
df.select("TIEMPO_CAMINO").describe().show()  
# 6ï¸âƒ£ Limpieza de datos
df_limpio = df.filter(
    (col("MEDIO_PREDOMINANTE").isNotNull()) &
    (col("TIEMPO_CAMINO").isNotNull()) &
    (col("TIEMPO_CAMINO") > 0)
)

print(f"\nğŸ§¹ Total de registros despuÃ©s de limpieza: {df_limpio.count()}")

# 7ï¸âƒ£ Transformaciones y anÃ¡lisis
# Conteo de viajes por medio de transporte
conteo = df_limpio.groupBy("MEDIO_PREDOMINANTE") \
    .agg(count("*").alias("NUM_VIAJES")) \
    .orderBy(desc("NUM_VIAJES"))

# Promedio de tiempo de viaje
promedios = df_limpio.groupBy("MEDIO_PREDOMINANTE") \
    .agg(round(avg("TIEMPO_CAMINO"), 2).alias("PROMEDIO_TIEMPO")) \
    .orderBy(col("PROMEDIO_TIEMPO").asc())

# 8ï¸âƒ£ DistribuciÃ³n porcentual de medios de transporte
total_viajes = df_limpio.count()
distribucion = conteo.withColumn("PORCENTAJE", round((col("NUM_VIAJES") / total_viajes) * 100, 2))

# 9ï¸âƒ£ Mostrar resultados en consola
print("\nğŸš— --- Conteo de viajes por medio de transporte ---")
conteo.show(truncate=False)

print("\nğŸ•’ --- Tiempo promedio de viaje por medio de transporte ---")
promedios.show(truncate=False)
 print("\nğŸ“Š --- DistribuciÃ³n porcentual de medios de transporte ---")
distribucion.show(truncate=False)

# ğŸ”Ÿ Guardar resultados
output_dir = "/home/vboxuser/datasets/encuesta_movilidad/resultados"
conteo.write.mode("overwrite").csv(f"{output_dir}/conteo_viajes", header=True)
promedios.write.mode("overwrite").csv(f"{output_dir}/promedio_tiempo", header=True)
distribucion.write.mode("overwrite").csv(f"{output_dir}/distribucion", header=True)

print("\nâœ… Procesamiento batch completado correctamente.")
print(f"ğŸ“‚ Resultados guardados en: {output_dir}")

# ğŸ”š Cerrar sesiÃ³n
spark.stop()
