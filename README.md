ğŸš¦ Proyecto de AnÃ¡lisis de Movilidad con Spark y Kafka

Autora: Andrea Gordillo Rojas
Universidad: UNAD â€“ Universidad Nacional Abierta y a Distancia
Asignatura: Big Data y AnalÃ­tica Avanzada
Entorno de ejecuciÃ³n: Ubuntu (VM en VirtualBox con Apache Spark, Kafka y Zookeeper instalados)

ğŸ§© 1. DefiniciÃ³n del problema y conjunto de datos

El proyecto tiene como propÃ³sito analizar la movilidad urbana en BogotÃ¡, utilizando la Encuesta de Movilidad 2019, con el fin de identificar patrones de viaje, medios de transporte predominantes y tiempos promedio de desplazamiento.

Se emplean herramientas del ecosistema Big Data â€”Apache Spark y Apache Kafkaâ€” para realizar un procesamiento batch y un procesamiento en tiempo real (streaming), demostrando cÃ³mo ambos enfoques se complementan en un escenario analÃ­tico completo.

ğŸ§¾ Conjunto de datos

Nombre: Movilidad de BogotÃ¡ â€“ CaracterizaciÃ³n de Viajes

Archivo: Encuesta_movilidad.csv

Fuente: Kaggle (Encuesta de Movilidad BogotÃ¡ 2019)[(https://www.kaggle.com/datasets/eduarmma19/movilidad-de-bogot-caracterizacin-viajes?resource=download)]

TamaÃ±o: ~43 MB

Formato: CSV

UbicaciÃ³n en la VM:

/home/vboxuser/datasets/Encuesta_movilidad.csv

ğŸ—‚ 2. Estructura de carpetas del proyecto

La organizaciÃ³n del proyecto dentro de la VM es la siguiente:

/home/vboxuser/
â”‚
â”œâ”€â”€ spark_output/                      â†’ Resultados del procesamiento en streaming
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ Encuesta_movilidad.csv         â†’ Conjunto de datos original
â”‚   â”œâ”€â”€ batch_process.py               â†’ Script de procesamiento batch (Spark)
â”‚   â””â”€â”€ encuesta_movilidad/
â”‚       â””â”€â”€ resultados/
â”‚           â”œâ”€â”€ promedio_tiempo/       â†’ Resultados del procesamiento batch
â”‚           â”œâ”€â”€ distribucion/          â†’ Resultados del procesamiento batch
â”‚           â””â”€â”€ conteo_viajes/         â†’ Resultados del procesamiento batch
â”‚
â”œâ”€â”€ kafka_producer.py                  â†’ Productor de Kafka (simula flujo de datos)
â””â”€â”€ spark_streaming_consumer.py        â†’ Consumidor Spark Streaming (procesamiento en tiempo real)


batch_process.py: Procesamiento batch con Spark (limpieza, anÃ¡lisis y almacenamiento).

kafka_producer.py: EnvÃ­a los datos del CSV a un tÃ³pico Kafka.

spark_streaming_consumer.py: Procesa los datos en tiempo real con Spark Streaming.

resultados/: Contiene los CSV generados por el anÃ¡lisis batch.

âš™ï¸ 3. Procesamiento Batch (Spark)

Script: datasets/batch_process.py

Este script realiza el anÃ¡lisis y transformaciÃ³n inicial del dataset de movilidad:

Funcionalidades principales:

Lectura del archivo CSV con Spark.

Limpieza de datos: eliminaciÃ³n de nulos y registros inconsistentes.

TransformaciÃ³n de columnas y conversiÃ³n de tipos.

CÃ¡lculo de indicadores principales:

Promedio de tiempo de viaje por medio de transporte.

Conteo de viajes por motivo.

DistribuciÃ³n horaria de los desplazamientos.

Almacenamiento de resultados en:

/home/vboxuser/datasets/encuesta_movilidad/resultados/
â”œâ”€â”€ promedio_tiempo/
â”œâ”€â”€ distribucion/
â””â”€â”€ conteo_viajes/

EjecuciÃ³n:
cd /home/vboxuser/datasets
python3 batch_process.py

Ejemplo de salida:
-------------------------------------------
Batch: 5
-------------------------------------------
+------------------+-------------+
|MEDIO_PREDOMINANTE|PROMEDIO_TIEMPO|
+------------------+-------------+
|Transmilenio      |27.35        |
|Bus urbano        |25.10        |
|Bicicleta         |15.87        |
|A pie             |12.43        |
+------------------+-------------+
Streaming (salida en tiempo real):

ğŸ”„ 4. Procesamiento en Tiempo Real (Streaming + Kafka)
âš™ï¸ Kafka Producer

Script: /home/vboxuser/kafka_producer.py

Simula la llegada de datos en tiempo real, publicando los registros del archivo Encuesta_movilidad.csv al tÃ³pico movilidad.

Pasos:

Leer el CSV.

Convertir cada fila en un mensaje JSON.

Enviar los mensajes al tÃ³pico Kafka.

EjecuciÃ³n:

python3 kafka_producer.py

âš™ï¸ Spark Streaming Consumer

Script: /home/vboxuser/spark_streaming_consumer.py

Escucha el tÃ³pico movilidad y procesa los mensajes en tiempo real con Spark Structured Streaming.

Tareas:

Conectarse al tÃ³pico Kafka movilidad.

Leer los mensajes JSON y estructurarlos como DataFrame.

Calcular conteos en tiempo real por medio de transporte.

Mostrar los resultados en consola y almacenarlos opcionalmente en /spark_output/.

EjecuciÃ³n:

spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  /home/vboxuser/spark_streaming_consumer.py

ğŸ§  5. Arquitectura de la SoluciÃ³n
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Encuesta_movilidad.csv (Kaggle)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ batch_process.py (Spark - Batch)          â”‚
             â”‚ Limpieza + EDA + Resultados CSV           â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                Resultados en: resultados/
                            â”‚
                            â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ kafka_producer.py                 â”‚
             â”‚ EnvÃ­a datos JSON a Kafka (topic)  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ spark_streaming_consumer.py       â”‚
             â”‚ Procesamiento en tiempo real      â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       Resultados en spark_output/

ğŸ“Š 6. Resultados Esperados
ğŸ”¹ Procesamiento Batch

Promedio de duraciÃ³n de viaje por medio de transporte.

Conteo de viajes por motivo (MOTIVOVIAJE).

DistribuciÃ³n horaria de viajes (HORA_INICIO, HORA_FIN).

ğŸ”¹ Procesamiento Streaming

Conteo en tiempo real de viajes segÃºn el medio de transporte.

Resultados actualizados en consola o almacenados en /spark_output/.

ğŸ“¸ 7. Capturas sugeridas para la presentaciÃ³n

Estructura de carpetas en /home/vboxuser/.

EjecuciÃ³n del script batch_process.py con Spark.

Productor Kafka enviando datos al tÃ³pico movilidad.

Spark Streaming recibiendo y mostrando resultados en tiempo real.

Archivos generados dentro de resultados/.

ğŸ”— 8. Enlaces

Repositorio GitHub: Proyecto de AnÃ¡lisis de Movilidad con Spark y Kafka

Video explicativo: (realizado por Andrea Gordillo Rojas, UNAD)

ğŸ’¬ 9. Conclusiones

Este proyecto demuestra el potencial del ecosistema Big Data al integrar Spark (para procesamiento masivo y analÃ­tico) y Kafka (para transmisiÃ³n y anÃ¡lisis en tiempo real).

La aplicaciÃ³n permite analizar la movilidad de BogotÃ¡ de forma flexible y escalable, aplicando una infraestructura que combina:

Limpieza y anÃ¡lisis batch de grandes volÃºmenes.

Procesamiento de flujos en tiempo real.

Persistencia de resultados para anÃ¡lisis posteriores.  
